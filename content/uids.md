Title: UIDs
Date: 2014-02-21 18:22
Category: Blog
Author: Joshua Ryan Smith
status: draft

A unique identifier allows people to unambiguously specify a thing. People typically use contextual idnetifiers: "this thing is next to that object which is yellow. Also, I put it there last week." There are a number of peoblems with this construction. Context depends in some part on the observer. Also, context can change without people knowing. A unique identifier is universal and is the same independent of context.

The best unique identifier would be made of some intrinsic property of the thing. Geographical coordinates might work in some cases. Temporal coordinates in others. USually physical properites might sufficie. Also acceptable is a completely random number, assuming only one number is assigned to a thing. A possibility for files on a filesystem is the checksum. I think that a unique idnetifier could fall into two classes: intrinsic and extrinsic. Intrinsic would mean that something like a physical property is used to idenitfy the thing. Extrinsic means that everybody agress that whatever arbitrary name is selected as a UID is the universally accepted standard.

I think that for labs, (small groups of researchers) intrinsic labeling schemes are probably impractical. I'd say that extrinsic labels made out of disjoint, useful metadata is the way to go.

Metadata is data about data. Lets say you record an XPS spectrum. Its likely that this data will be a set of ordered pairs of numbers: one number corresponding to the pass energy and one corresponding to the count. This is all well and good, but at a human, you are going to need more information. What sample does this data correspond to? Who recorded the data? When was the data collected? What was the base pressure of the system? What anode was used? Etc. All of this other stuff is metadata. This metadata is what gives humans a fighting chance of contexutalizing the data. It therefore means that researchers aren't wasting their time. Metadata is useful both for humans and computers. The stuff you write in your lab notebook about an eperiment can be considered to be metadata. Metadata can be of any type: numerical textual, etc. You want ao regimented way of collecting metadtaa because I'd rgue that your data is useless without it. What I just said: data is the most valueable thing, but data without metadata is of zero value.

All of the things I've been describing are about metadata more than they are about actual data. I'm describing a consistant and regimented way of managing metadata in order to add the most value ot your data. In this way, I'm describing a system whcih can have automation easily applied and can therefore boost productivity and efficiency: for the same time/money investment (grants, postdocs, grad students) you can have a 2x or even 100x return above not using the system.

The lab notebook entries are a longform narrabitve form of metadara. The sample logs are an index-line collection of relevant metadtaa. Even teh filenames are constructed from metaedata. Thi ssytem is set up with the sufficienciet crosslinking to make auditing possible and even easy. The system is set up so that its machine friendly also: you pay a one-time machine cost plus electricity and the machines can crawl through your stuff and return results that are too mind-numbing for a human.

Next I want to write up what Randy calls, "run sheets". These are a practical form of automation. Basically, there are a set of setps that are repeated often enough that its worthwhile to write them down. Also, they describe a process. Also they are a checklist and serve to reduce a human's cognitive load. I did something similar when I was at CMU: At the beginning of the day, I'd make a list of steps for experiments I was planning on conducting. In this way, I'd have an addressible record (e.g. lab notebook name, page number) that I could refer back to if necessary. lso, I would front-load all of the thinking about the experiments in instead of howing to make critical decisions in the heat of the moment during an experiment (when time and resources are at stake). I would essentially simulate the experiment, going over the decision tree in advance adn choosing the best path, with sufficient time to game out plan B scenarios. I should mention as an aside: this kind of planning just doesn't look or feel like real work. Real work seems like it is being in the lab, unbolting things or pressing buttons. However, all of this planning *is* real work and is actually mroe efficient than that hands-on-beakers stuff in the lab because you have the chance of generalizing it. This isn't to say that hands-on-beakers isn't valueable or that you should minimize it -- its important that you don't. Hands-on-beakers time is valueable because that is precisely how you acquire experience.

Run sheets and automation can be a scylla and charybdis: you can spend 100% of your time planning things to the nth detail and therefore never achieve your goal because you didn't spend the hands-on beakers time to actually do the work. Another pitfall on this side of the balance is to try to make infinitely detailed run sheets for absolutely everything you do. This sort of overhead doesn't make sense for experiments that are one-off. However, if you find that you are doing essentially the same thing more than four times, you should probably invest the time to make a run sheet. Even if you are convinced absolutely that you will only do an experiment once, you can spend 15 minutes gaming the scenario out just to uncover any unforeseen pitfalls.

The other side of this coin is spending zero time on planning/run sheets and 100% of your time with your hands on beakers. In this case you can end up spending ultimately more time on your experiments because you never identify and eliminate small time-wasters.

There are several powerful and general principles here: one is that work is divided into a thinking part and a doing part. There's a quote: a week in the lab can save you an hour in the library. Second is automation. Scientific work is the last great bastion of artisinal labor. Most experiments are done by hand. However, as soon as you notice a pattern forming, develop a routine and automate it. Note: it is incredibly useful to have a trusted system to organize all of this stuff. I recommend GTD.

Automation lends itself nicely to delegation. As soon as you can automate a process, you can delegate it to another person or a computer. Delegating to a computer is programming. Delegating to other people carries a stigma, some find. If you have that problem, get over it as fast as you can. Delegating things to your future self is also a possibility.
